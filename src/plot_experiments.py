"""
Deep Inverse Q-Learning with Constraints. NeurIPS 2020.
Gabriel Kalweit, Maria Huegle, Moritz Werling and Joschka Boedecker
Neurorobotics Lab, University of Freiburg.

This script creates figures of experiments for IAVI and IQL. Please specify the number of trajectories you want to evaluate. 
If you change the number of epochs for IQL, please update the output_iql parameter in the main function below. 
 
python plot_experiments.py no_traj
"""

import os, sys
import glob
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from mdp.value_iteration import find_policy

font = {'family' : 'serif',
        'weight' : 'bold',
        'size'   : 12}
plt.rc('font', **font)
plt.rc('text', usetex=True)



def policy_eval(policy, reward, transition_probabilities, nS, nA, discount_factor=1.0, theta=0.00001):
    """
    Policy Evaluation.
    """
    V = np.zeros(nS)
    while True:
        delta = 0
        for s in range(nS):
            v = 0
            for a, a_prob in enumerate(policy[s]):
                if a_prob == 0.0:
                    continue
                ns_prob = transition_probabilities[s, a]
                next_v = V[np.arange(nS)]
                r = reward[s]
                v += np.sum(ns_prob * a_prob * (r + discount_factor * next_v))
            delta = max(delta, np.abs(v - V[s]))
            V[s] = v
        print(delta)
        if delta < theta:
            break
    return np.array(V)
   

def plot_grid(trajectories, v1, v2, v3, v4, grid_size):
    """
    Plot grid.    
    """
    fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(7,2))
    axes[0].imshow(v1.reshape(grid_size, grid_size), vmin=v1.min(), vmax=v1.max())
    axes[0].set_title("Optimal", fontsize="x-large")

    axes[1].imshow(v2.reshape(grid_size, grid_size), vmin=v2.min(), vmax=v2.max())
    axes[1].set_title("Ground Truth", fontsize="x-large")

    axes[2].set_title("IAVI", fontsize="x-large")
    im = axes[2].imshow(v2.reshape(grid_size, grid_size), vmin=v2.min(), vmax=v2.max())

    axes[3].set_title("IQL", fontsize="x-large")
    im = axes[3].imshow(v3.reshape(grid_size, grid_size), vmin=v3.min(), vmax=v3.max())

    axes[0].axes.get_xaxis().set_visible(False)
    axes[1].axes.get_xaxis().set_visible(False)
    axes[2].axes.get_xaxis().set_visible(False)
    axes[3].axes.get_xaxis().set_visible(False)
    axes[0].axes.get_yaxis().set_visible(False)
    axes[1].axes.get_yaxis().set_visible(False)
    axes[2].axes.get_yaxis().set_visible(False)
    axes[3].axes.get_yaxis().set_visible(False)

    axes[0].text(-5, 15, "%s Trajectories" %n_traj, rotation=90, verticalalignment='center', usetex=True)

    fig.tight_layout(rect=[0, 0.03, 1, 0.95])
    plt.savefig(os.path.join("../results/imgs/", "%d_result.png" %(trajectories)), bbox_inches='tight')


def read_results(path):
    """
    Read results from path.
    """
    files = glob.glob(os.path.join(path, "*.npy"))
    settings = dict()
    for f in files:
        name = os.path.basename(f).split(".")[0]
        settings[name] = np.load(f)
    return settings["boltzmann"], settings["runtime"]


if __name__ == '__main__':

    # number of trajectories to evaluate.
    n_traj = int(sys.argv[1])

    output_iavi = "../results/objectworld_%d_trajectories/objectworld_%d_trajectories_set_0/iavi_1/" %(n_traj,n_traj)
    output_iql = "../results/objectworld_%d_trajectories/objectworld_%d_trajectories_set_0/iql_100/" % (n_traj,n_traj)


    # Objectworld settings.
    grid_size = 32
    nS = grid_size**2
    nA = 5

    # load data from experiments generated by train.py.
    data_file = "objectworld_%s_trajectories"%n_traj
    data_dir = os.path.join("../data", data_file, "objectworld_%s_trajectories_set_0"%n_traj)

    feature_matrix = np.load(os.path.join(data_dir, "feature_matrix.npy"))
    trajectories = np.load(os.path.join(data_dir, "trajectories.npy"))
    action_probabilities = np.load(os.path.join(data_dir, "action_probabilities.npy"))
    transition_probabilities = np.load(os.path.join(data_dir, "transition_probabilities.npy"))
    ground_r= np.load(os.path.join(data_dir, "ground_r.npy"))
    p_start_state = np.load(os.path.join(data_dir, "p_start_state.npy"))

    # compute state-values.
    b, iavi_runtime = read_results(output_iavi)
    v_iavi = policy_eval(b, ground_r, transition_probabilities, nS, nA, discount_factor=0.9, theta=0.001)

    b, iql_runtime = read_results(output_iql)
    v_iql = policy_eval(b, ground_r, transition_probabilities, nS, nA, discount_factor=0.9, theta=0.001)

    # compute ground truth distribution.
    v_true = policy_eval(action_probabilities, ground_r, transition_probabilities, nS, nA, discount_factor=0.9, theta=0.001) 

    # compute optimal distribution.
    b = find_policy(nS, nA, transition_probabilities, ground_r, discount=0.9, threshold=1e-2)
    v_real = policy_eval(b, ground_r, transition_probabilities, nS, nA, discount_factor=0.9, theta=0.001) 

    print("IAVI Runtime:  %0.2f" % (iavi_runtime/ 3600.))
    print("IQL Runtime: %0.2f" % (iql_runtime / 3600.))
    print("IAVI EVD:  %0.2f" % np.square(v_real - v_iavi).mean())
    print("IQL EVD:  %0.2f" % np.square(v_real - v_iql).mean())

    # create images.
    plot_grid(n_traj, v_real, v_true, v_iavi, v_iql, grid_size)


    # create result table.
    path = "../results/results.csv"
    if os.path.exists(path):
        df = pd.read_csv(path)
    else:
        df = pd.DataFrame(columns=["Number of Trajectories", "EVD IAVI", "EVD IQL", "Runtime IAVI [h]", "Runtime IQL [h]"])
    
    df.loc[len(df)] =  [ n_traj, np.square(v_real - v_iavi).mean(), np.square(v_real - v_iql).mean(), (iavi_runtime/ 3600.), (iql_runtime/ 3600.)]
   

    df.round(3).to_csv(path, index=False)
    print(df.round(3))
